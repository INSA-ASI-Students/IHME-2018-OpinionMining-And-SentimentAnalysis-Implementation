{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./StanceDataset/test_ingrid.csv')\n",
    "df_train = pd.read_csv('./StanceDataset/train_ingrid.csv')\n",
    "\n",
    "test_tweet = df_test['Tweet']\n",
    "train_tweet = df_train['Tweet']\n",
    "\n",
    "train_sentiment = df_train['Sentiment']\n",
    "test_sentiment = df_test['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste = []\n",
    "\n",
    "ListeTweet = df_train.Tweet.values.tolist()\n",
    "ListSentiment = df_train.Sentiment.values.tolist()\n",
    "dim = len(ListSentiment)\n",
    "i = 0\n",
    "#print(dim)\n",
    "\n",
    "while i < dim:\n",
    "    tmp = (ListeTweet[i], ListSentiment[i])\n",
    "    liste.append(tmp)\n",
    "    i += 1\n",
    "\n",
    "#Liste de tuples (tweet,sentiment)\n",
    "#print(liste)\n",
    "\n",
    "# liste : Liste(tweet entier, sentiment)\n",
    "\n",
    "\n",
    "tweets = []\n",
    "\n",
    "for (words, sentiment) in liste:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 2]  #1 pour avoir bcp de mot split\n",
    "    tweets.append((words_filtered, sentiment))\n",
    "\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "\n",
    "word_features = get_word_features(get_words_in_tweets(tweets))\n",
    "\n",
    "\n",
    "tokens = get_words_in_tweets(tweets)\n",
    "freq = nltk.FreqDist(tokens) \n",
    "#for key,val in freq.items(): \n",
    "   #print (str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_posTweet = []\n",
    "X_train_negTweet = []\n",
    "X_train_otherTweet = []\n",
    "\n",
    "X_test_posTweet = []\n",
    "X_test_negTweet = []\n",
    "X_test_otherTweet = []\n",
    "\n",
    "\n",
    "dim = len(df_train)\n",
    "dim = len(df_test)\n",
    "\n",
    "for i in range(dim):\n",
    "    if train_sentiment[i] == 'pos':\n",
    "        X_train_posTweet.append(train_tweet[i])\n",
    "    elif train_sentiment[i] == 'neg':\n",
    "        X_train_negTweet.append(train_tweet[i])\n",
    "    elif  train_sentiment[i] == 'other':\n",
    "        X_train_otherTweet.append(train_tweet[i])\n",
    "\n",
    "for i in range(dim):        \n",
    "    if test_sentiment[i] == 'pos':\n",
    "        X_test_posTweet.append(test_sentiment[i])\n",
    "    elif  test_sentiment[i] == 'neg':\n",
    "        X_test_negTweet.append(test_sentiment[i])\n",
    "    elif  test_sentiment[i] == 'other':\n",
    "        X_test_otherTweet.append(test_sentiment[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_wordPos = []\n",
    "X_train_wordNeg = []\n",
    "X_train_wordOther = []\n",
    "\n",
    "X_test_wordPos = []\n",
    "X_test_wordNeg = []\n",
    "X_test_wordOther = []\n",
    "\n",
    "\n",
    "for (words) in X_train_posTweet:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 6]  #6 : longueur des mots que l'on prends\n",
    "    X_train_wordPos.append(words_filtered)\n",
    "\n",
    "\n",
    "for (words) in X_train_negTweet:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 6]  #6 : longueur des mots que l'on prends\n",
    "    X_train_wordNeg.append(words_filtered)\n",
    "    \n",
    "\n",
    "for (words) in X_train_otherTweet:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 6]  #6 : longueur des mots que l'on prends\n",
    "    X_train_wordOther.append(words_filtered)\n",
    "    \n",
    "\n",
    "    \n",
    "for (words) in X_test_posTweet:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 6]  #6 : longueur des mots que l'on prends\n",
    "    X_test_wordPos.append(words_filtered)\n",
    "\n",
    "\n",
    "for (words) in X_test_negTweet:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 6]  #6 : longueur des mots que l'on prends\n",
    "    X_test_wordNeg.append(words_filtered)\n",
    "    \n",
    "\n",
    "for (words) in X_test_otherTweet:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 6]  #6 : longueur des mots que l'on prends\n",
    "    X_test_wordOther.append(words_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.03067484662577\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    " \n",
    "positive_features_train = [(word_feats(pos), 'pos') for pos in X_train_wordPos]\n",
    "negative_features_train = [(word_feats(neg), 'neg') for neg in X_train_wordNeg]\n",
    "neutral_features_train = [(word_feats(other), 'other') for other in X_train_wordOther]\n",
    "\n",
    "positive_features_test = [(word_feats(pos), 'pos') for pos in X_test_wordPos]\n",
    "negative_features_test = [(word_feats(neg), 'neg') for neg in X_test_wordNeg]\n",
    "neutral_features_test = [(word_feats(other), 'other') for other in X_test_wordOther]\n",
    " \n",
    "train_set = negative_features_train + positive_features_train + neutral_features_train\n",
    "test_set = negative_features_test + positive_features_test + neutral_features_test\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "#print(nltk.classify.accuracy(classifier,test_set))\n",
    "\n",
    "accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
    "print(accuracy * 100)\n",
    "#classifier.show_most_informative_features()\n",
    "# ACCURACY : taux de bonne pr√©diction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHODE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
